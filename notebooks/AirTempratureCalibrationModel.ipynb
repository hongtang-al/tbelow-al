{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ebc3cf",
   "metadata": {},
   "source": [
    "## Air Temperature Calibration Model Development "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63bca24d",
   "metadata": {},
   "source": [
    "**Task Description**\n",
    "\n",
    "**Goal:** \\\n",
    "    The goal of a calibration model is to improve the accuracy and reliability of one of our sensorâ€™s outputs. \\\n",
    "**Assignment:** \\\n",
    "    Primary objective is to output a value for air temperature that is more accurate and reliable than the raw value from our main air temperature sensors\n",
    "    \n",
    "**Assessment:** \\\n",
    "It can take many days or weeks to develop a reliable and performant calibration model prototype. This assignment will not be assessed by the performance of the final model. It will be assessed on:\n",
    "-\tDemonstrating a thorough understanding of the problem space\n",
    "-\tProficiency in data handling and manipulation\n",
    "-\tDemonstrating a structured model development process\n",
    "-\tEffectively evaluating model(s)/solution(s) \n",
    "-\tAbility to communicate process and findings\n",
    "-\tA performant model is a plus!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926321af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "###need to check\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "\n",
    "# Import packages for model building\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=pd.read_csv('data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reference file \n",
    "# dic=dic[['File','Name','Description']]\n",
    "# dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensor dataframe\n",
    "df=pd.read_csv('mark_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a38c89",
   "metadata": {},
   "source": [
    "### Data OVerView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a689d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df618265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicate records: No duplicates\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432ae77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check missing value: lwdw are mostly missing could be removed\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8eb53",
   "metadata": {},
   "source": [
    "### drop lwdw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop missing column\n",
    "df.drop(['lwdw'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54571aa3",
   "metadata": {},
   "source": [
    "### Independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change time to timestamp\n",
    "df.time = pd.to_datetime(df.time, errors='coerce')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dqs.value_counts()\n",
    "#dqs can be convert to category data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6359da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dqs=pd.Categorical(df.dqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.device.value_counts()\n",
    "#there are 5 unique devices could be used to group data \n",
    "df.device=pd.Categorical(df.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group data by categories for later modeling\n",
    "float_v = list(df.select_dtypes(include=['float64']).columns)\n",
    "cat_v = list(df.select_dtypes(include=['category']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_v, cat_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21691d8",
   "metadata": {},
   "source": [
    "### change time to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c83b80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[df['dqs']==4]['b1dw'].plot()\n",
    "# cannot find dqs description and move ahead with caution now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e69d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dqs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name=df.device.value_counts().reset_index()\n",
    "\n",
    "cats=list(device_name.iloc[:,0]) \n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114723f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name=df.device.value_counts().reset_index()\n",
    "\n",
    "cats=list(device_name.iloc[:,0]) \n",
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c13123",
   "metadata": {},
   "source": [
    "### Batch visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5197fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot data in batch to QC\n",
    "def quick_look(df, cat_name, cats, props):\n",
    "    '''\n",
    "    plot all property:props plots by cats:category\n",
    "    '''\n",
    "    for cat in cats:\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.plot(df[df[cat_name]==cat][props])\n",
    "        ax.set_xlabel(cats, fontsize=15)\n",
    "        ax.set_ylabel(props, fontsize=15)\n",
    "quick_look(df, 'device', cats, 'temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ff59a",
   "metadata": {},
   "source": [
    "***Note**: there are some outlier 60C C004894 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c50d27",
   "metadata": {},
   "source": [
    "### some outlier plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temps(df, device, prop):\n",
    "    '''\n",
    "    input dataframe, category(such as devices)\n",
    "    property(such as temprature)\n",
    "    '''\n",
    "    \n",
    "    plt.plot(df[df.device==device][prop])\n",
    "    ax.set_xlabel( device, fontsize=15)\n",
    "    ax.set_ylabel(prop, fontsize=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture some outliers plots\n",
    "fig, ax = plt.subplots()\n",
    "plot_temps(df,'C004894','therm_temp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae73b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_temps(df,'C004894','temp' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7465a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_temps(df,'C005348','therm_temp' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "#     print(q1, q3, fence_low,fence_high)\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers simplified approach. could you 3 sigma approach. After tested no difference in this dataset\n",
    "#outlier handling should be build in pipeline to streamline for deployment\n",
    "float_v_outliers=['temp', 'temp_sd', 'therm_temp', 'therm_temp_sd', 'p', 't_u14']\n",
    "for feature in float_v_outliers:\n",
    "    df = remove_outlier(df, feature)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd53dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[df.device=='C004894']['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91794c1f",
   "metadata": {},
   "source": [
    "### Uni Variate Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d12b4",
   "metadata": {},
   "source": [
    "### plot histograms for quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88c78b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "# nrows=2\n",
    "nrows = int(np.ceil(len(df.columns) / (1.0*ncols)))\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 12))\n",
    "\n",
    "# Lazy counter so we can remove unwated axes\n",
    "counter = 0\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "\n",
    "        ax = axes[i][j]\n",
    "\n",
    "        # Plot when we have data\n",
    "        if counter < len(df.columns):\n",
    "\n",
    "            ax.hist(df[df.columns[counter]], bins=20, color='red', alpha=0.5, label='{}'.format(df.columns[counter]))\n",
    "#             ax.set_xlabel('x')\n",
    "#             ax.set_ylabel('PDF')\n",
    "#             ax.set_ylim([0, 5])\n",
    "            leg = ax.legend(loc='upper right')\n",
    "            leg.draw_frame(False)\n",
    "\n",
    "        # Remove axis when we no longer have data\n",
    "        else:\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eca02c",
   "metadata": {},
   "source": [
    "### boxplot  for quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd94e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16,8.27)})\n",
    "fig.tight_layout()\n",
    "# float_v.remove('lwdw')\n",
    "# float_v.remove('p')\n",
    "\n",
    "sns.boxplot(data=df[float_v])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ec943",
   "metadata": {},
   "source": [
    "***Note:*** lwuw, swdw, swuw still has significant outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d414f",
   "metadata": {},
   "source": [
    "### Independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref=pd.read_csv('reference_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to map site with device\n",
    "\n",
    "devSite={'AZ_LTER': 'C004991',\n",
    " 'NREL': 'C004988',\n",
    " 'ESALQ': 'C004894',\n",
    " 'US-Los': 'C006826',\n",
    " 'US-Seg': 'C005348'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69279fa",
   "metadata": {},
   "source": [
    "#### create new column device in reference df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d911010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref['device']=df_ref.site_id.apply(lambda x: devSite[x] if x in devSite else x )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e01a7",
   "metadata": {},
   "source": [
    "#### convert types: time, object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ffb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.ref_time = pd.to_datetime(df_ref.ref_time, errors='coerce')\n",
    "df_ref.device=pd.Categorical(df_ref.device)\n",
    "df_ref.site_id=pd.Categorical(df_ref.site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.rename(columns={'ref_time':'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53574657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_copy=df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6433c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ref_copy.groupby('device').resample('D')['ref_tair'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f56ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_ref_copy.ref_tair.plot()\n",
    "# fig = plt.figure(figsize=(12,4)) \n",
    "\n",
    "# sns.lineplot(data=df_ref_copy.ref_tair, color='blue', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8339fff",
   "metadata": {},
   "source": [
    "#### join mark data and df_ref using device and time to create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df.copy()\n",
    "#this step is time consuming activate when necessary\n",
    "# df_new=pd.merge(df_ref, df_copy,  how='right', on=['time','device'])\n",
    "#https://towardsdatascience.com/how-to-merge-not-matching-time-series-with-pandas-7993fcbce063\n",
    "df_ref = df_ref.sort_values(['time'])\n",
    "df_copy = df_copy.sort_values(['time'])\n",
    "df_new=pd.merge_asof(df_ref, df_copy,  on='time', by='device',tolerance=pd.Timedelta('10min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.info()\n",
    "df_ref.shape, df_new.shape, df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266acf8",
   "metadata": {},
   "source": [
    "***Note:*** looks like we are able to get most data matched and assigned. lets remove nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e96ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# more options can be specified also\n",
    "df_new1=df_new[~df_new['ref_tair'].isnull()& ~df_new['temp'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df01c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5188534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e734ba",
   "metadata": {},
   "source": [
    "#### We miss significant portion of data during merging even though we tried timedelta approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bbecd",
   "metadata": {},
   "source": [
    "#### We may want to revisit before deadline. Now let's move on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac544506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new1.describe()\n",
    "#df_new1.info()\n",
    "# df_new1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c45dba",
   "metadata": {},
   "source": [
    "***Note*** Let's create a heatmap to check dependent and independent variables relationship "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1.columns\n",
    "#group data by categories for later modeling\n",
    "float_v = list(df_new1.select_dtypes(include=['float64']).columns)\n",
    "cat_v = list(df_new1.select_dtypes(include=['category']).columns)\n",
    "cat_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bd9b5",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b037d9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# printmd('**independent and dependent variables, which features have high correlation with dependent var. and how about colinearlity?**')\n",
    "sns.set(style=\"white\")\n",
    "features=float_v\n",
    "corr = df_new1[features].corr()\n",
    "\n",
    "#Generate a mask for the upper triangle:\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "#Set up the matplotlib figure and a diverging colormap:\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "#Draw the heatmap with the mask and correct aspect ratio:\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.9, center=0, annot=False, \n",
    "square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67c429",
   "metadata": {},
   "source": [
    "***Note:*** \n",
    "1. very strong colinearalities amond bxdw features\n",
    "2. strong colinearlities among temprature measurements\n",
    "3. colinearlity should be handled at modeling stage\n",
    "4. reference temprature has strong correlation with temp, therm_temp, lwuw,swuw, t_u14, t_u21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a566b67",
   "metadata": {},
   "source": [
    "# 1. Dummy Transformer for Categorical Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678aefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since site_id and device are one to one match, we can drop device\n",
    "df_new1.drop(['device'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cat_v.remove('device')\n",
    "cat_features=['site_id', 'dqs']\n",
    "df_new1 = pd.get_dummies(df_new1, columns=cat_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9985a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279e89a",
   "metadata": {},
   "source": [
    "# 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f2fb5",
   "metadata": {},
   "source": [
    "#### random split to train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# features\n",
    "features=df_new1.columns.tolist()\n",
    "target='ref_tair'\n",
    "features.remove(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df_new1.columns.tolist()\n",
    "target='ref_tair'\n",
    "features.remove(target)\n",
    "X=df_new1[features]\n",
    "y=df_new1[target]\n",
    "\n",
    "# split into train/test sets with same class ratio\n",
    "X_train, X_test, y_train, y_test =    train_test_split(X, y, test_size=0.3,\n",
    "                     random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46389e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[('rescale', MinMaxScaler()),\n",
    "       ('pca', PCA(n_components=10)),\n",
    "       ('lr', Lasso(alpha=1, max_iter=100000))]\n",
    "#        ('rfr', RandomForestRegressor(random_state=0))]\n",
    "pipe=Pipeline(steps)\n",
    "pipe = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d441b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=pipe.predict(X_train)\n",
    "y_test_pred=pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c651cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "print('test MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('test MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('test R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(pipe.steps[1][1].feature_importances_, index=X_train.columns)\n",
    "feat_importances.sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d05a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgdf = (df_new1.reset_index()\n",
    "#           .groupby(['time','device'], as_index=False)\n",
    "#           .mean()\n",
    "# #           # rename isn't strictly necessary here, it's just for readability\n",
    "# #           .rename(columns={'index':'ct'})\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51be2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # key gives the group name (i.e. category), data gives the actual values\n",
    "# for key, data in df_new1.groupby('device'):\n",
    "#     data.plot(x='time', y='ref_tair', ax=ax, label=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(df_new1.groupby(['device'])['ref_tair'])\n",
    "# # plt.plot(df_new1['temp'])\n",
    "# # plt.plot(df_new1['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f0623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
